from datetime import datetime
import glob
import os
import shutil
import sys
import subprocess

import pandas as pd
from snakemake.utils import min_version


from seqnado.design import Design, ATACOutput, NormGroups
from seqnado.helpers import format_config_dict, symlink_fastq_files, remove_unwanted_run_files, run_batch_job_on_error


####################
# Hardcoded config #
####################

ASSAY = "ATAC"
SCALE_RESOURCES = float(os.environ.get("SCALE_RESOURCES", "1"))

configfile: "config_atac.yml"
container: "oras://ghcr.io/alsmith151/seqnado_pipeline:latest"


####################
# Experiment config #
####################

# Load config
format_config_dict(config)

# Generate design
if os.path.exists(config["design"]):
    df = pd.read_csv(config["design"], sep=r"\s+|,|\t", engine="python").fillna("")
    DESIGN = Design.from_dataframe(df)
else:
    DESIGN = Design.from_directory(".")

# Attempt to symlink the fastq files
assert len(DESIGN.fastq_paths) > 0, "No fastq files found in the working directory or no design file provided."
symlink_fastq_files(DESIGN, output_dir="seqnado_output/fastqs")


# Define global variables
SAMPLE_NAMES = DESIGN.sample_names
OUTPUT = ATACOutput(
    assay=ASSAY,
    config=config,
    run_design=DESIGN,
    sample_names=SAMPLE_NAMES,
    **config
)

NORMALISATION_SCALING = NormGroups.from_design(DESIGN, subset_column="norm_group", include_controls=True)
NORMALISATION_MERGING = NormGroups.from_design(DESIGN, subset_column="merge", include_controls=True)

###################
# Pipeline config #
###################

include: "rules/common.smk"
include: "rules/align.smk"
include: "rules/alignment_post_processing.smk"
include: "rules/fastq_screen.smk"
include: "rules/fastq_trim.smk"
include: "rules/pileup_default.smk"
include: "rules/pileup_norm.smk"
include: "rules/pileup_grouped.smk"
include: "rules/peak_call_other.smk"
include: "rules/peak_call_grouped.smk"
include: "rules/qc.smk"
include: "rules/heatmap.smk"
include: "rules/hub.smk"
include: "rules/geo_submission.smk"
include: "rules/visualisation.smk"
include: "rules/consensus_counts.smk"
include: "rules/dataset.smk"

rule all:
    input:
        OUTPUT.files

onsuccess:
    remove_unwanted_run_files()

onerror:
    log_out = "seqnado_error.log"
    shutil.copyfile(log, log_out)
    print(
        f"An error occurred. Please check the log file {log_out} for more information."
    )

    # # Check we can send an error email
    # can_email = subprocess.run(["which", 'sbatch'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL).returncode == 0
    # can_email = can_email and config['ucsc_hub_details'].get('email', None)

    # if can_email:
    #     run_batch_job_on_error(config['ucsc_hub_details']['email'])
    
    
    remove_unwanted_run_files()