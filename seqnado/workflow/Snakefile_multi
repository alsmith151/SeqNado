"""
Master Snakefile for running multiple SeqNado assays in a single project.

This workflow orchestrates running multiple assays (ChIP, ATAC, RNA, etc.) 
with outputs organized by assay type under seqnado_output/{assay}/.

Usage:
    snakemake -s workflow/Snakefile_multi --cores 32

Design Note:
This is a simplified orchestrator that runs each assay's pipeline sequentially
or in parallel. For true parallel execution within a single DAG, the main 
Snakefile would need modification to accept an output_prefix parameter.
"""

import os
from pathlib import Path
import yaml

################################
# Auto-detect assay configs
################################

def find_assay_configs(directory="."):
    """Find all config_{assay}.yaml files in the directory."""
    config_files = {}
    for config_file in Path(directory).glob("config_*.yaml"):
        assay_name = config_file.stem.replace("config_", "")
        
        # Load config to verify it's valid
        try:
            with open(config_file) as f:
                cfg = yaml.safe_load(f)
                config_files[assay_name] = {
                    'path': str(config_file.absolute()),
                    'config': cfg
                }
        except Exception as e:
            print(f"Warning: Could not load {config_file}: {e}")
            
    return config_files


# Discover available assays
ASSAY_CONFIGS = find_assay_configs()
ASSAYS = sorted(list(ASSAY_CONFIGS.keys()))

if not ASSAYS:
    raise ValueError(
        "No config_*.yaml files found in the current directory. "
        "Please create config files using 'seqnado config <assay>'"
    )

print(f"[Multi-Assay Mode] Detected {len(ASSAYS)} assay(s): {', '.join(ASSAYS)}")

# Validate metadata files exist
for assay in ASSAYS:
    metadata_file = Path(f"metadata_{assay}.csv")
    if not metadata_file.exists():
        raise FileNotFoundError(
            f"Missing metadata file: {metadata_file}\n"
            f"Please create it using 'seqnado design {assay}'"
        )
    print(f"  ✓ {assay}: {ASSAY_CONFIGS[assay]['path']} + {metadata_file}")


################################
# Configuration
################################

OUTPUT_DIR = "seqnado_output/"

# Get workflow arguments and cores from top-level command
WORKFLOW_ARGS = config.get("workflow_args", "--use-singularity --printshellcmds --rerun-incomplete")
# Get cores from config, default to all available
CORES = config.get("cores", 16)  # Default to 16 if not specified


################################
# Master rule - runs all assays
################################

rule all:
    input:
        expand(OUTPUT_DIR + "{assay}/logs/.complete", assay=ASSAYS)
    default_target: True


################################
# Per-assay execution
################################

rule run_assay:
    """
    Execute a single assay pipeline with outputs in seqnado_output/{assay}/
    
    This runs the main Snakefile with modified output paths.
    Runs as a regular rule (not checkpoint) to enable parallel execution of multiple assays.
    """
    output:
        complete = OUTPUT_DIR + "{assay}/logs/.complete",
        report = OUTPUT_DIR + "{assay}/seqnado_report.html"
    params:
        assay = lambda wildcards: wildcards.assay,
        config_file = lambda wildcards: str(Path(ASSAY_CONFIGS[wildcards.assay]['path']).resolve()),
        metadata = lambda wildcards: str(Path(f"metadata_{wildcards.assay}.csv").resolve()),
        main_snakefile = str(Path(workflow.basedir) / "Snakefile"),
        output_dir = OUTPUT_DIR + "{assay}",
        project_root = str(Path.cwd())
    log:
        OUTPUT_DIR + "{assay}/logs/snakemake.log"
    threads: CORES  # Use all available cores for nested snakemake
    resources:
        mem_mb = 16000,  # Allocate some memory for the orchestration step
        runtime = 259200  # 3 days in seconds
    shell:
        """
        # Create output directory
        mkdir -p {params.output_dir}/logs
        
        echo "================================================================" | tee {log}
        echo "Starting {params.assay} pipeline at $(date)" | tee -a {log}
        echo "Config: {params.config_file}" | tee -a {log}
        echo "Metadata: {params.metadata}" | tee -a {log}
        echo "Output: {params.output_dir}" | tee -a {log}
        echo "================================================================" | tee -a {log}
        
        # Run the main SeqNado Snakefile for this assay
        # Create assay-specific .snakemake directory to prevent locking conflicts
        mkdir -p .snakemake/{params.assay}
        
        # Use --directory to isolate .snakemake metadata in assay-specific subdirectory
        # The .snakemake dir will be created at .snakemake/{assay}/.snakemake
        cd .snakemake/{params.assay} && \
        snakemake \
            --snakefile {params.main_snakefile} \
            --configfile {params.config_file} \
            --config output_dir=../../{params.output_dir} metadata={params.metadata} \
            --cores {threads} \
            {WORKFLOW_ARGS} \
            2>&1 | tee -a ../../{log}
        
        # Mark completion (from .snakemake/{assay}/ so need ../../ prefix)
        touch ../../{output.complete}
        
        echo "================================================================" | tee -a ../../{log}
        echo "Completed {params.assay} pipeline at $(date)" | tee -a ../../{log}
        echo "Report: ../../{output.report}" | tee -a ../../{log}
        echo "================================================================" | tee -a ../../{log}
        """


################################
# Summary and reporting
################################

rule summary:
    """Generate a summary report of all assays."""
    input:
        expand(OUTPUT_DIR + "{assay}/logs/.complete", assay=ASSAYS)
    output:
        "multi_assay_summary.txt"
    run:
        with open(output[0], 'w') as f:
            f.write("SeqNado Multi-Assay Project Summary\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"Total assays: {len(ASSAYS)}\n")
            f.write(f"Assays: {', '.join(ASSAYS)}\n\n")
            
            for assay in ASSAYS:
                f.write(f"\n{assay.upper()}\n")
                f.write("-" * 50 + "\n")
                f.write(f"  Config:   {ASSAY_CONFIGS[assay]['path']}\n")
                f.write(f"  Metadata: metadata_{assay}.csv\n")
                f.write(f"  Output:   seqnado_output/{assay}/\n")
                
                # Check for report
                report_file = Path(OUTPUT_DIR + "{assay}/seqnado_report.html")
                if report_file.exists():
                    f.write(f"  Report:   ✓ seqnado_output/{assay}/seqnado_report.html\n")
                else:
                    f.write(f"  Report:   ✗ Not found\n")

