name: Python package

on: [push]

jobs:
  setup-package:
    name: Setup SeqNado Package
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Get current date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Cache conda environment
        id: cache-conda
        uses: actions/cache@v3
        with:
          path: |
            ~/conda_pkgs_dir
            /usr/share/miniconda3/envs/test
          key: ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-${{ github.run_number }}-${{ steps.get-date.outputs.date }}
          restore-keys: |
            ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-
            ${{ runner.os }}-conda-

      - name: Setup Conda environment
        uses: conda-incubator/setup-miniconda@v3
        if: steps.cache-conda.outputs.cache-hit != 'true'
        with:
          environment-file: testing.yml
          miniforge-version: latest
          use-mamba: true

      - name: Activate conda environment for package installation
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: test
          miniforge-version: latest
          use-mamba: true

      - name: Install SeqNado package
        shell: bash -el {0}
        run: |
          # Verify conda environment is active
          echo "Active conda environment: $CONDA_DEFAULT_ENV"
          echo "Python executable: $(which python)"
          
          # Verify pytest is available (should be from testing.yml)
          python -c "import pytest; print(f'pytest version: {pytest.__version__}')" || {
            echo "pytest not found - installing via pip"
            pip install pytest
          }
          
          # Install SeqNado package into the conda environment
          pip install .

      - name: Create conda environment artifact
        shell: bash -el {0}
        run: |
          # Verify SeqNado is installed correctly
          python -c "import seqnado; print(f'SeqNado installed at: {seqnado.__file__}')"
          which seqnado-init || echo "seqnado-init not found in PATH"
          python -c "import pytest; print(f'pytest version: {pytest.__version__}')"
          
          echo "Environment verification complete - ready to create artifact"
          echo "Conda environment location: $CONDA_PREFIX"
          echo "Conda environment name: $CONDA_DEFAULT_ENV"
          
          # Create a temporary directory structure that mirrors what we need
          mkdir -p /tmp/conda-env-artifact
          cp -r "$CONDA_PREFIX"/* /tmp/conda-env-artifact/
          
          echo "Artifact preparation complete"
          ls -la /tmp/conda-env-artifact

      - name: Upload complete conda environment
        uses: actions/upload-artifact@v4
        with:
          name: conda-environment-test
          path: /tmp/conda-env-artifact
          retention-days: 1

  cache-containers:
    name: Cache Container Images
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Get current date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Restore cached conda environment
        id: cache-conda
        uses: actions/cache@v3
        with:
          path: |
            ~/conda_pkgs_dir
            /usr/share/miniconda3/envs/test
          key: ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-${{ github.run_number }}-${{ steps.get-date.outputs.date }}
          restore-keys: |
            ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-
            ${{ runner.os }}-conda-

      - name: Setup Conda environment
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: test
          miniforge-version: latest
          use-mamba: true

      - name: Cache container images
        id: cache-singularity
        uses: actions/cache@v3
        with:
          path: |
            ~/.apptainer
            ~/.apptainer/cache
            ~/apptainer_images
          key: ${{ runner.os }}-apptainer-containers-v5-${{ hashFiles('seqnado/workflow/snakefile_*', 'seqnado/workflow/rules/*.smk') }}
          restore-keys: |
            ${{ runner.os }}-apptainer-containers-v5-
            ${{ runner.os }}-apptainer-containers-

      - name: Setup Apptainer runtime
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        uses: eWaterCycle/setup-apptainer@v2
        with:
          apptainer-version: 1.3.4

      - name: Configure Sylabs Cloud remote
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          apptainer remote add --no-login SylabsCloud cloud.sylabs.io
          apptainer remote use SylabsCloud

      - name: Create container cache directories
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p ~/apptainer_images
          mkdir -p ~/.apptainer/cache

      - name: Download and cache container images
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        env:
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          echo "Downloading Apptainer images with Snakemake-compatible naming..."
          
          # Create the container directory that Snakemake expects
          mkdir -p $HOME/apptainer_images
          
          # Calculate MD5 hashes and pull containers with those names (using .simg extension)
          python3 -c "
          import hashlib
          import subprocess
          import os
          
          containers = [
              'oras://ghcr.io/alsmith151/seqnado_pipeline:latest',
              'oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 
              'docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3',
              'library://asmith151/plotnado/plotnado:latest',
              'library://asmith151/lanceotron/lanceotron-mcc:latest'
          ]
          
          for url in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              output_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              print(f'Downloading {url} -> {hash_value}.simg')
              subprocess.run(['apptainer', 'pull', output_path, url], check=True)
          "
          
          echo "Container download complete:"
          ls -la $HOME/apptainer_images/

      - name: Verify container cache integrity
        shell: bash
        run: |
          echo "Verifying container cache integrity..."
          echo "Contents of ~/apptainer_images:"
          ls -la ~/apptainer_images/ || echo "Directory doesn't exist"
          echo "Contents of ~/.apptainer/cache:"
          ls -la ~/.apptainer/cache/ || echo "Directory doesn't exist"
          
          # Verify specific hash-named containers exist and count them dynamically
          python3 -c "
          import hashlib
          import os
          
          containers = [
              ('oras://ghcr.io/alsmith151/seqnado_pipeline:latest', 'Main pipeline'),
              ('oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 'ML'),
              ('docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3', 'MACS2'),
              ('library://asmith151/plotnado/plotnado:latest', 'Plotnado'),
              ('library://asmith151/lanceotron/lanceotron-mcc:latest', 'Lanceotron-MCC')
          ]
          
          expected_count = len(containers)
          found_count = 0
          
          for url, name in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              container_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              if os.path.exists(container_path):
                  print(f'✓ {name} container found ({hash_value}.simg)')
                  found_count += 1
              else:
                  print(f'✗ {name} container missing ({hash_value}.simg)')
          
          print(f'Container verification: {found_count}/{expected_count} containers found')
          if found_count == expected_count:
              print('✅ All expected containers are cached successfully')
          else:
              print(f'⚠️  Warning: Expected {expected_count} containers but found {found_count}')
          "
          
          # Count the number of .simg files as backup check
          simg_count=$(find ~/apptainer_images -name "*.simg" 2>/dev/null | wc -l)
          echo "Total .simg files in cache: $simg_count"

  test-pipelines:
    name: Test Pipeline - ${{ matrix.assay }}
    needs: [setup-package, cache-containers]
    if: github.event_name == 'pull_request' || github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        assay: ["atac", "chip-rx", "chip", "rna-rx", "rna", "snp", 'cat', 'meth', 'mcc']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Get current date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Restore cached conda environment
        id: cache-conda
        uses: actions/cache@v3
        with:
          path: |
            ~/conda_pkgs_dir
            /usr/share/miniconda3/envs/test
          key: ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-${{ github.run_number }}-${{ steps.get-date.outputs.date }}
          restore-keys: |
            ${{ runner.os }}-conda-${{ hashFiles('testing.yml') }}-
            ${{ runner.os }}-conda-

      - name: Download complete conda environment
        uses: actions/download-artifact@v4
        with:
          name: conda-environment-test
          path: /tmp/conda-env-downloaded

      - name: Restore conda environment to correct location
        shell: bash
        run: |
          # Create the conda environment directory
          sudo mkdir -p /usr/share/miniconda3/envs/test
          
          # Copy the downloaded environment to the correct location
          sudo cp -r /tmp/conda-env-downloaded/* /usr/share/miniconda3/envs/test/
          
          echo "Conda environment restored to /usr/share/miniconda3/envs/test"
          ls -la /usr/share/miniconda3/envs/test

      - name: Setup Conda environment (use artifact)
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: test
          miniforge-version: latest
          use-mamba: true

      - name: Verify restored environment
        shell: bash -el {0}
        run: |
          echo "Python environment verification:"
          which python
          python --version
          echo "Conda environment: $CONDA_DEFAULT_ENV"
          echo "Conda prefix: $CONDA_PREFIX"
          
          echo "Checking for pytest:"
          python -c "import pytest; print(f'pytest version: {pytest.__version__}')"
          
          echo "Checking for SeqNado:"
          which seqnado-init
          python -c "import seqnado; print(f'SeqNado found at: {seqnado.__file__}')"
          
          echo "Environment restoration verified successfully"

      - name: Setup Apptainer runtime
        uses: eWaterCycle/setup-apptainer@v2
        with:
          apptainer-version: 1.3.4

      - name: Verify cached containers are available
        shell: bash
        run: |
          echo "Verifying cached containers are available for pipeline tests:"
          ls -la ~/apptainer_images/ || echo "No containers found"
          
          # Dynamic container count verification
          python3 -c "
          import hashlib
          import os
          
          containers = [
              ('oras://ghcr.io/alsmith151/seqnado_pipeline:latest', 'Main pipeline'),
              ('oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 'ML'),
              ('docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3', 'MACS2'),
              ('library://asmith151/plotnado/plotnado:latest', 'Plotnado'),
              ('library://asmith151/lanceotron/lanceotron-mcc:latest', 'Lanceotron-MCC')
          ]
          
          expected_count = len(containers)
          found_count = 0
          
          for url, name in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              container_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              if os.path.exists(container_path):
                  found_count += 1
          
          # Quick count check
          try:
              simg_count = len([f for f in os.listdir(f'{os.environ[\"HOME\"]}/apptainer_images') if f.endswith('.simg')])
          except FileNotFoundError:
              simg_count = 0
          
          print(f'Expected containers: {expected_count}')
          print(f'Found .simg files: {simg_count}')
          
          if simg_count >= expected_count:
              print('✅ All expected containers are available')
          else:
              print(f'⚠️  Warning: Expected {expected_count} containers but found {simg_count}')
          "

      - name: Run SeqNado pipeline test for ${{ matrix.assay }}
        shell: bash -el {0}
        env:
          TMPDIR: /tmp
          SEQNADO_CONFIG: "${{ github.workspace }}/tests/genome_config.json"
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          # Use python -m pytest to ensure proper module resolution
          python -m pytest tests/test_pipelines.py::test_pipeline[${{ matrix.assay }}] -vv -s --cores 4