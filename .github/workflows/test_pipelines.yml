name: Python package

on: [push]

jobs:
  setup-package:
    name: Setup SeqNado Package
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Conda environment
        uses: conda-incubator/setup-miniconda@v3
        with:
          environment-file: testing.yml
          miniforge-version: latest

      - name: Install SeqNado package
        shell: bash
        run: |
          # Install to user site-packages to avoid permission issues
          pip install --user .

      - name: Create complete package installation artifact
        shell: bash
        run: |
          # Get the user site-packages directory (writable)
          USER_SITE_PACKAGES=$(python -c "import site; print(site.getusersitepackages())")
          echo "User site-packages location: $USER_SITE_PACKAGES"
          
          # Create artifact directory
          mkdir -p package_artifact
          
          # Copy the user site-packages directory if it exists
          if [ -d "$USER_SITE_PACKAGES" ]; then
            cp -r "$USER_SITE_PACKAGES" package_artifact/user-site-packages
            echo "Copied user site-packages"
          else
            echo "User site-packages directory not found"
            mkdir -p package_artifact/user-site-packages
          fi
          
          # Also capture any conda environment site-packages
          CONDA_SITE_PACKAGES=$(python -c "import site; print([p for p in site.getsitepackages() if 'conda' in p or 'miniconda' in p][0] if any('conda' in p or 'miniconda' in p for p in site.getsitepackages()) else '')")
          if [ -n "$CONDA_SITE_PACKAGES" ] && [ -d "$CONDA_SITE_PACKAGES" ]; then
            echo "Found conda site-packages: $CONDA_SITE_PACKAGES"
            cp -r "$CONDA_SITE_PACKAGES" package_artifact/conda-site-packages
          fi
          
          # Save environment details
          echo "$USER_SITE_PACKAGES" > package_artifact/user_site_packages_path.txt
          echo "$CONDA_SITE_PACKAGES" > package_artifact/conda_site_packages_path.txt
          python -c "import sys; print(sys.executable)" > package_artifact/sys_executable.txt
          python -c "import sys; print(sys.version)" > package_artifact/python_version.txt
          python -c "import site; print('\\n'.join(site.getsitepackages()))" > package_artifact/all_site_packages_paths.txt
          
          echo "Package installation artifact created"
          ls -la package_artifact/

      - name: Upload complete package installation
        uses: actions/upload-artifact@v4
        with:
          name: seqnado-complete-install
          path: package_artifact/

  test-pipelines:
    name: Test Pipeline - ${{ matrix.assay }}
    needs: setup-package
    if: github.event_name == 'pull_request' || github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        assay: ["atac", "chip-rx", "chip", "rna-rx", "rna", "snp", 'cat', 'meth', 'mcc']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Conda environment
        uses: conda-incubator/setup-miniconda@v3
        with:
          environment-file: testing.yml
          miniforge-version: latest

      - name: Download complete package installation
        uses: actions/download-artifact@v4
        with:
          name: seqnado-complete-install
          path: package_artifact/

      - name: Restore SeqNado package from artifact
        shell: bash
        run: |
          # Get the current user site-packages directory
          USER_SITE_PACKAGES=$(python -c "import site; print(site.getusersitepackages())")
          echo "Target user site-packages: $USER_SITE_PACKAGES"
          
          # Ensure the user site-packages directory exists
          mkdir -p "$USER_SITE_PACKAGES"
          
          # Restore the user site-packages from artifact
          if [ -d "package_artifact/user-site-packages" ]; then
            echo "Restoring user site-packages installation..."
            cp -r package_artifact/user-site-packages/* "$USER_SITE_PACKAGES/" 2>/dev/null || echo "No user site-packages to restore"
          fi
          
          # Also restore conda site-packages if available
          if [ -d "package_artifact/conda-site-packages" ]; then
            # Get the current conda site-packages path
            CONDA_SITE_PACKAGES=$(python -c "import site; print([p for p in site.getsitepackages() if 'conda' in p or 'miniconda' in p][0] if any('conda' in p or 'miniconda' in p for p in site.getsitepackages()) else '')")
            if [ -n "$CONDA_SITE_PACKAGES" ]; then
              echo "Restoring conda site-packages to: $CONDA_SITE_PACKAGES"
              cp -r package_artifact/conda-site-packages/* "$CONDA_SITE_PACKAGES/" 2>/dev/null || echo "No conda site-packages to restore"
            fi
          fi
          
          # Enable user site-packages if not already enabled
          export PYTHONNOUSERSITE=
          
          # Verify SeqNado is available
          python -c "import seqnado; print(f'SeqNado restored successfully from: {seqnado.__file__}')" || echo "SeqNado not found, may need fallback installation"
          
          echo "Package restoration complete"

      # Container setup for pipeline tests
      - name: Cache container images
        id: cache-singularity
        uses: actions/cache@v3
        with:
          path: |
            ~/.apptainer
            ~/.apptainer/cache
            ~/apptainer_images
          key: ${{ runner.os }}-apptainer-containers-v5-${{ hashFiles('seqnado/workflow/snakefile_*', 'seqnado/workflow/rules/*.smk') }}
          restore-keys: |
            ${{ runner.os }}-apptainer-containers-v5-
            ${{ runner.os }}-apptainer-containers-

      - name: Setup Apptainer runtime
        uses: eWaterCycle/setup-apptainer@v2
        with:
          apptainer-version: 1.3.4

      - name: Configure Sylabs Cloud remote
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          apptainer remote add --no-login SylabsCloud cloud.sylabs.io
          apptainer remote use SylabsCloud

      - name: Create container cache directories
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p ~/apptainer_images
          mkdir -p ~/.apptainer/cache

      - name: Download and cache container images
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        env:
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          echo "Downloading Apptainer images with Snakemake-compatible naming..."
          
          # Create the container directory that Snakemake expects
          mkdir -p $HOME/apptainer_images
          
          # Calculate MD5 hashes and pull containers with those names (using .simg extension)
          python3 -c "
          import hashlib
          import subprocess
          import os
          
          containers = [
              'oras://ghcr.io/alsmith151/seqnado_pipeline:latest',
              'oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 
              'docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3',
              'library://asmith151/plotnado/plotnado:latest',
              'library://asmith151/lanceotron/lanceotron-mcc:latest'
          ]
          
          for url in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              output_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              print(f'Downloading {url} -> {hash_value}.simg')
              subprocess.run(['apptainer', 'pull', output_path, url], check=True)
          "
          
          echo "Container download complete:"
          ls -la $HOME/apptainer_images/

      - name: Verify cached containers are available
        shell: bash
        run: |
          echo "Verifying cached containers are available for pipeline tests:"
          ls -la ~/apptainer_images/ || echo "No containers found"
          
          # Dynamic container count verification
          python3 -c "
          import hashlib
          import os
          
          containers = [
              ('oras://ghcr.io/alsmith151/seqnado_pipeline:latest', 'Main pipeline'),
              ('oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 'ML'),
              ('docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3', 'MACS2'),
              ('library://asmith151/plotnado/plotnado:latest', 'Plotnado'),
              ('library://asmith151/lanceotron/lanceotron-mcc:latest', 'Lanceotron-MCC')
          ]
          
          expected_count = len(containers)
          found_count = 0
          
          for url, name in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              container_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              if os.path.exists(container_path):
                  found_count += 1
          
          # Quick count check
          try:
              simg_count = len([f for f in os.listdir(f'{os.environ[\"HOME\"]}/apptainer_images') if f.endswith('.simg')])
          except FileNotFoundError:
              simg_count = 0
          
          print(f'Expected containers: {expected_count}')
          print(f'Found .simg files: {simg_count}')
          
          if simg_count >= expected_count:
              print('✅ All expected containers are available')
          else:
              print(f'⚠️  Warning: Expected {expected_count} containers but found {simg_count}')
          "

      - name: Run SeqNado pipeline test for ${{ matrix.assay }}
        shell: pwsh
        env:
          TMPDIR: /tmp
          SEQNADO_CONFIG: "${{ github.workspace }}/tests/genome_config.json"
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          pytest tests/test_pipelines.py::test_pipeline[${{ matrix.assay }}] -vv -s --cores 4