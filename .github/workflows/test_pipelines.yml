name: Python package

on: [push]

jobs:
  cache-containers:
    runs-on: ubuntu-latest
    outputs:
      cache-hit: ${{ steps.cache-singularity.outputs.cache-hit }}
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: true

      - name: Cache singularity
        id: cache-singularity
        uses: actions/cache@v3
        with:
          path: |
            ~/.apptainer
            ~/.apptainer/cache
            ~/apptainer_images
          key: ${{ runner.os }}-apptainer-containers-v5-${{ hashFiles('seqnado/workflow/snakefile_*', 'seqnado/workflow/rules/*.smk') }}
          restore-keys: |
            ${{ runner.os }}-apptainer-containers-v5-
            ${{ runner.os }}-apptainer-containers-

      - uses: eWaterCycle/setup-apptainer@v2
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        with:
          apptainer-version: 1.3.4

      - name: Add singularity hub remote
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          apptainer remote add --no-login SylabsCloud cloud.sylabs.io
          apptainer remote use SylabsCloud

      - name: Setup apptainer cache directory
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p ~/apptainer_images
          mkdir -p ~/.apptainer/cache

      - name: Debug container hashing
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: python
        run: |
          import hashlib
          
          containers = [
              "oras://ghcr.io/alsmith151/seqnado_pipeline:latest",
              "oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest", 
              "docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3",
              "library://asmith151/plotnado/plotnado:latest",
              "library://asmith151/lanceotron/lanceotron-mcc:latest"
          ]
          
          print("Snakemake container hashes:")
          for url in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              print(f"{url} -> {hash_value}.simg")

      - name: Pull singularity images
        if: steps.cache-singularity.outputs.cache-hit != 'true'
        shell: bash
        env:
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          echo "Pulling all required Apptainer images with Snakemake-compatible naming..."
          
          # Create the container directory that Snakemake expects
          mkdir -p $HOME/apptainer_images
          
          # Calculate MD5 hashes and pull containers with those names (using .simg extension)
          python3 -c "
          import hashlib
          import subprocess
          import os
          
          containers = [
              'oras://ghcr.io/alsmith151/seqnado_pipeline:latest',
              'oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 
              'docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3',
              'library://asmith151/plotnado/plotnado:latest',
              'library://asmith151/lanceotron/lanceotron-mcc:latest'
          ]
          
          for url in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              output_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              print(f'Pulling {url} -> {hash_value}.simg')
              subprocess.run(['apptainer', 'pull', output_path, url], check=True)
          "
          
          echo "Containers pulled with Snakemake-compatible hash names:"
          ls -la $HOME/apptainer_images/

      - name: Verify containers are cached
        shell: bash
        run: |
          echo "Contents of ~/apptainer_images:"
          ls -la ~/apptainer_images/ || echo "Directory doesn't exist"
          echo "Contents of ~/.apptainer/cache:"
          ls -la ~/.apptainer/cache/ || echo "Directory doesn't exist"
          
          # Verify specific hash-named containers exist
          python3 -c "
          import hashlib
          import os
          
          containers = [
              ('oras://ghcr.io/alsmith151/seqnado_pipeline:latest', 'Main pipeline'),
              ('oras://ghcr.io/alsmith151/seqnado_ml_cpu:latest', 'ML'),
              ('docker://quay.io/biocontainers/macs2:2.2.9.1--py39hbcbf7aa_3', 'MACS2'),
              ('library://asmith151/plotnado/plotnado:latest', 'Plotnado'),
              ('library://asmith151/lanceotron/lanceotron-mcc:latest', 'Lanceotron-MCC')
          ]
          
          found_count = 0
          for url, name in containers:
              md5hash = hashlib.md5(usedforsecurity=False)
              md5hash.update(url.encode())
              hash_value = md5hash.hexdigest()
              container_path = f'{os.environ[\"HOME\"]}/apptainer_images/{hash_value}.simg'
              
              if os.path.exists(container_path):
                  print(f'✓ {name} container found ({hash_value}.simg)')
                  found_count += 1
              else:
                  print(f'✗ {name} container missing ({hash_value}.simg)')
          
          print(f'Total containers found: {found_count}/5')
          "
          
          # Count the number of .simg files as backup check
          simg_count=$(find ~/apptainer_images -name "*.simg" 2>/dev/null | wc -l)
          echo "Total .simg files found: $simg_count"

  Test:
    needs: cache-containers
    if: github.event_name == 'pull_request' || github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test: ["config", "design", "pipeline"]
        assay: ["atac", "chip-rx", "chip", "rna-rx", "rna", "snp", 'cat', 'meth', 'mcc']

    steps:
      - uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          environment-file: testing.yml
          miniforge-version: latest

      - name: Install package
        shell: pwsh
        run: |
          pip install .

      - name: Restore cached containers
        if: matrix.test == 'pipeline'
        id: cache-singularity
        uses: actions/cache@v3
        with:
          path: |
            ~/.apptainer
            ~/.apptainer/cache
            ~/apptainer_images
          key: ${{ runner.os }}-apptainer-containers-v5-${{ hashFiles('seqnado/workflow/snakefile_*', 'seqnado/workflow/rules/*.smk') }}
          restore-keys: |
            ${{ runner.os }}-apptainer-containers-v5-
            ${{ runner.os }}-apptainer-containers-

      - uses: eWaterCycle/setup-apptainer@v2
        if: matrix.test == 'pipeline'
        with:
          apptainer-version: 1.3.4

      - name: Verify cached containers available
        if: matrix.test == 'pipeline'
        shell: bash
        run: |
          echo "Verifying cached containers are available:"
          ls -la ~/apptainer_images/ || echo "No containers found"
          
          # Quick count check
          simg_count=$(find ~/apptainer_images -name "*.simg" 2>/dev/null | wc -l)
          echo "Found $simg_count .simg files"
          
          if [ "$simg_count" -lt 5 ]; then
            echo "⚠️  Warning: Expected 5 containers but found $simg_count"
          else
            echo "✅ All containers appear to be cached"
          fi

      - name: Test ${{ matrix.test }} ${{ matrix.assay }}
        shell: pwsh
        env:
          TMPDIR: /tmp
          SEQNADO_CONFIG: "${{ github.workspace }}/tests/genome_config.json"
          APPTAINER_CACHEDIR: "$HOME/.apptainer/cache"
        run: |
          pytest tests/test_pipelines.py::test_${{ matrix.test }}[${{ matrix.assay }}] -vv -s --cores 4