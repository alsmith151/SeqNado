{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Pipeline based on snakemake to process ChIP-seq (with optional spike-in based normalisation), ATAC-seq, RNA-seq and short read WGS data for SNP calling. The defaults are optimised for the Milne group directory on the CCB cluster, but can be easily modified for other groups and clusters.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<p>The installation page has detailed instructions for installing SeqNado. For a very quick start, run the following command:</p> <pre><code>mamba install -c bioconda seqnado\n</code></pre>"},{"location":"#set-up-the-pipeline","title":"Set up the pipeline","text":""},{"location":"#config-file","title":"Config file","text":"<p>Generate the config file and a working directory for the pipeline:</p> <pre><code>seqnado-config [atac|chip|rna|snp]\n</code></pre>"},{"location":"#ensure-files-are-in-the-correct-location","title":"Ensure files are in the correct location","text":"<p>Ensure that the fastq files, and design are in the correct location:</p> <pre><code># Fastq files\nln -s /path/to/fastq_files/* /path/to/working-directory/made-by-seqnado-config/fastq/\n</code></pre>"},{"location":"#design-optional","title":"Design (optional)","text":"<p>The design will be generated automatically if not provided and the samples follow the correct naming convention.</p> <pre><code>cd /path/to/working-directory/made-by-seqnado-config/\nseqnado-design [atac|chip|rna|snp]\n</code></pre>"},{"location":"#run-the-pipeline","title":"Run the pipeline","text":"<pre><code>cd /path/to/working-directory/made-by-seqnado-config/\nseqnado [atac|chip|rna|snp] -c &lt;number of cores&gt; --preset [ss|ls] \n# ss = use cluster, ls = use local (not recommended)\n# additional options\n--queue/-q [short|long] --scale-resource/-s &lt;factor to multiply resources&gt; \n\n# An actual example would be:\nseqnado rna -c 8 --preset ss\n</code></pre>"},{"location":"cluster_config/","title":"Set-up a Snakemake profile","text":"<p>This is not essential but it will make running the pipeline much easier by submitting jobs to the cluster automatically and using pre-set parameters.</p> <p>Note: Cookiecutter is required for this step. This can be installed using <code>pip install cookiecutter</code>.</p>"},{"location":"cluster_config/#for-slurm-based-clusters","title":"For SLURM based clusters:","text":"<pre><code># create config directory that snakemake searches for profiles (or use something else)\nprofile_dir=\"${HOME}/.config/snakemake\"\nmkdir -p \"$profile_dir\"\n# use cookiecutter to create the profile in the config directory\ntemplate=\"gh:Snakemake-Profiles/slurm\"\ncookiecutter --output-dir \"$profile_dir\" \"$template\"\n</code></pre>"},{"location":"cluster_config/#for-sge-based-clusters","title":"For SGE based clusters:","text":"<p>Warning</p> <p>This has not been tested</p> <pre><code>mkdir -p ~/.config/snakemake\ncd ~/.config/snakemake\ncookiecutter https://github.com/Snakemake-Profiles/sge.git\n</code></pre>"},{"location":"cluster_config/#example-slurm-profile","title":"Example SLURM profile:","text":"<pre><code>/home/a/asmith/.config/snakemake/slurm/\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 CookieCutter.py\n\u251c\u2500\u2500 __pycache__\n\u2502   \u251c\u2500\u2500 CookieCutter.cpython-310.pyc\n\u2502   \u251c\u2500\u2500 CookieCutter.cpython-311.pyc\n\u2502   \u251c\u2500\u2500 slurm_utils.cpython-310.pyc\n\u2502   \u2514\u2500\u2500 slurm_utils.cpython-311.pyc\n\u251c\u2500\u2500 settings.json\n\u251c\u2500\u2500 slurm-jobscript.sh\n\u251c\u2500\u2500 slurm-sidecar.py\n\u251c\u2500\u2500 slurm-status.py\n\u251c\u2500\u2500 slurm-submit.py\n\u2514\u2500\u2500 slurm_utils.py\n</code></pre> <p><code>settings.json</code>:</p> <pre><code>{\n    \"SBATCH_DEFAULTS\": \"--partition=short --time=0-01:00:00 --mem=3G\",\n    \"CLUSTER_NAME\": \"\",\n    \"CLUSTER_CONFIG\": \"\"\n}\n</code></pre> <p><code>config.yaml</code>:</p> <pre><code>cluster-sidecar: \"slurm-sidecar.py\"\ncluster-cancel: \"scancel\"\nrestart-times: \"0\"\njobscript: \"slurm-jobscript.sh\"\ncluster: \"slurm-submit.py\"\ncluster-status: \"slurm-status.py\"\nmax-jobs-per-second: \"10\"\nmax-status-checks-per-second: \"10\"\nlocal-cores: 1\nlatency-wait: \"5\"\nuse-conda: \"True\"\nuse-singularity: \"False\"\nsingularity-args: -B /ceph  -B /databank -B $TMPDIR --cleanenv\njobs: \"50\"\nprintshellcmds: \"True\"\nretries: 3\n\n# Example resource configuration\n# default-resources:\n#   - runtime=100\n#   - mem_mb=6000\n#   - disk_mb=1000000\n# # set-threads: map rule names to threads\n# set-threads:\n#   - single_core_rule=1\n#   - multi_core_rule=10\n# # set-resources: map rule names to resources in general\n# set-resources:\n#   - high_memory_rule:mem_mb=12000\n#   - long_running_rule:runtime=1200\n</code></pre> <p>Note: The singularity-args are required to mount the data directories into the container. e.g.</p> <pre><code>singularity-args: -B /ceph  -B /databank\n</code></pre> <p>Gives the container access to the <code>/ceph</code> and <code>/databank</code> directories on the cluster. The current working directory is also mounted into the container by default. You can add additional directories by adding more <code>-B</code> flags. Obviously this will be different for each cluster so you'll need your own defaults. The <code>$TMPDIR</code> is also mounted as this causes errors if not. The <code>--cleanenv</code> flag is also required to prevent the container from inheriting the environment from the host.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#pipeline-initialisation","title":"Pipeline initialisation","text":""},{"location":"faq/#workflow-defines-configfile-config_chipyml-but-it-is-not-present-or-accessible","title":"Workflow defines configfile config_chip.yml but it is not present or accessible.","text":"<p>This error occurs when the pipeline is run without a config file present in the working directory. Ensure that seqnado-config has been run before starting the pipeline and that you are in the new directory created by seqnado-config.</p> <p>Follow the Pipeline Setup instructions to create a config file.</p>"},{"location":"faq/#singularity-configuration","title":"Singularity configuration","text":""},{"location":"faq/#workflow-error","title":"Workflow Error","text":"<p>Failed to pull singularity image from library://asmith151/seqnado/seqnado_pipeline:latest: FATAL: Unable to get library client configuration: remote has no library client (see https://apptainer.org/docs/user/latest/endpoint.html#no-default-remote)</p> <p>Fix:</p> <p>re-run seqnado-init: Here</p> <p>or</p> <pre><code>apptainer remote add --no-login SylabsCloud cloud.sylabs.io  \napptainer remote use SylabsCloud  \n</code></pre>"},{"location":"faq/#optional-configuration","title":"Optional configuration","text":""},{"location":"faq/#can-i-merge-multiple-samples-into-a-single-sample","title":"Can I merge multiple samples into a single sample?","text":"<p>Yes, you can merge multiple samples into a single sample to generate merged bigWig files and consensus peaks. To do this, you need to create a design file that specifies the samples to be merged. The design file should have a column named \"merge\" that specifies the samples to be merged e.g.:</p> sample r1 r2 deseq2 merge rna1 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna1_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna1_1.fastq.gz control control rna2 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna2_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna2_1.fastq.gz control control rna3 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna3_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna3_1.fastq.gz control control rna4 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna4_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna4_1.fastq.gz treated treated rna5 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna5_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna5_1.fastq.gz treated treated rna6 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna6_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna6_1.fastq.gz treated treated"},{"location":"installation/","title":"Installation","text":"<p>The recommended way to install SeqNado is via a combination of conda and pip, this will ensure that all dependencies are installed correctly in a virtual environment. Using the recommended method, the main dependencies of the pipeline are accessed from a singularity container, so it is not necessary to install these manually. If required, conda can be used to install the dependencies locally, but this is not recommended.</p>"},{"location":"installation/#set-up","title":"Set-up","text":""},{"location":"installation/#check-condamamba-is-installed","title":"Check conda|mamba is installed","text":"<p>Ideally, ensure that mamba is installed and is working correctly.</p> <pre><code>which mamba\n</code></pre> <p>You should see something like:</p> <pre><code>/ceph/project/milne_group/asmith/software/mambaforge/condabin/mamba\n</code></pre>"},{"location":"installation/#install-mamba-if-required","title":"Install mamba (if required)","text":"<p>If mamba is not installed, install it using the following command:</p> <p>Warning</p> <p>Ensure that this is installed in your /project directory, not your home directory! These environments can be very large and will fill up your home directory very quickly.</p> <pre><code>curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\n\nbash Miniforge3-$(uname)-$(uname -m).sh\n</code></pre>"},{"location":"installation/#quick-installation","title":"Quick installation","text":"<pre><code>mamba create -n seqnado -c bioconda seqnado -y\nmamba activate seqnado\n</code></pre>"},{"location":"installation/#seqnado-init","title":"SeqNado init","text":"<p>quickly initialise seqnado </p> <pre><code>seqnado-init\n# options \n--preset # will copy the genome paths used internally in the Milne group\n</code></pre>"},{"location":"installation/#detailed-installation-for-advanced-users-or-troubleshooting","title":"Detailed installation for advanced users or troubleshooting","text":""},{"location":"installation/#create-a-conda-environment","title":"Create a conda environment","text":"<p>Create a basic conda environment (with pip to install python packages) and activate it.</p> <pre><code>mamba create -n seqnado pip \"python&gt;=3.12\"\nconda activate seqnado\n</code></pre>"},{"location":"installation/#install-the-pipeline","title":"Install the pipeline","text":""},{"location":"installation/#install-the-package-from-pip","title":"Install the package from pip","text":"<pre><code>pip install seqnado\n</code></pre>"},{"location":"installation/#ensure-that-environment-variables-are-set","title":"Ensure that Environment variables are set","text":"<p>Ensure that the environment variables are set correctly. This can be done by adding the following to your <code>.bashrc</code> or <code>.bash_profile</code>. Run this command to add the environment variables to your <code>.bashrc</code>:</p> <pre><code>echo 'export APPTAINER_BINDPATH=\"/ceph:/ceph, /project:/project, /databank:/databank\"' &gt;&gt; ~/.bashrc\n</code></pre> <p>Reload the <code>.bashrc</code> file:</p> <pre><code>source ~/.bashrc\n</code></pre> <p>Alternatively, start a new terminal session.</p>"},{"location":"installation/#install-from-github-directly","title":"Install from GitHub directly","text":"<p>To install the latest version of the pipeline from GitHub (main branch), use the following command:</p> <pre><code>pip install git+https://github.com/alsmith151/SeqNado.git\n</code></pre> <p>You can also install a specific branch e.g. <code>develop</code>:</p> <pre><code>pip install git+https://github.com/alsmith151/SeqNado.git@develop\n</code></pre>"},{"location":"installation/#install-from-a-local-copy-of-the-repository","title":"Install from a local copy of the repository","text":"<p>Clone the repositry and install directly.</p> <pre><code>git clone https://github.com/alsmith151/SeqNado.git\ncd SeqNado\npip install .\n</code></pre>"},{"location":"installation/#install-the-dependencies-if-required","title":"Install the dependencies (if required)","text":"<p>Assuming the conda environment is activated, install the dependencies using the following command:</p> <pre><code>wget https://raw.githubusercontent.com/alsmith151/SeqNado/main/environment.yml\nmamba env update -f environment.yml\n</code></pre>"},{"location":"pipeline/","title":"Pipeline","text":""},{"location":"pipeline/#configuration","title":"Configuration","text":"<p>The pipeline is configured using a YAML file: e.g. <code>config_atac.yml</code>, <code>config_chip.yml</code>. We highly recommend using the <code>seqnado-config</code> command to generate the configuration file as this will prompt the user for the required information and ensure that the configuration file is valid. The configuration file can be edited manually if required e.g. using <code>nano</code> or the VS Code text editor.</p>"},{"location":"pipeline/#generate-the-working-directory-and-configuration-file","title":"Generate the working directory and configuration file","text":"<p>The following command will generate the working directory and configuration file for the ATAC-seq pipeline:</p> <pre><code>seqnado-config chip\n\n# options \n-r, --rerun # Re-runs the config in existing seqnado directory\n</code></pre> <p>You should get something like this:</p> <pre><code>$ seqnado-config chip\n  What is your project name? [cchahrou_project]: cchahrou_project\n  What is the genome? [hg38]: hg38\n  Perform fastqscreen? (yes/no) [no]: yes\n  Path to fastqscreen config: [/PATH/TO/fastq_screen.conf]: /PATH/TO/fastq_screen.conf\n  Do you want to remove blacklist regions? (yes/no) [yes]: yes\n  Remove PCR duplicates? (yes/no) [yes]: yes\n  Remove PCR duplicates method: [picard/samtools]: picard\n  Calculate library complexity? (yes/no) [no]: yes\n  Do you have spikein? (yes/no) [no]: yes\n  Normalisation method: [orlando/with_input]: orlando\n  Reference genome: [hg38]: hg38\n  Spikein genome: [dm6]: dm6\n  Do you want to make bigwigs? (yes/no) [no]: yes\n  Pileup method: [deeptools/homer]: deeptools\n  Do you want to make heatmaps? (yes/no) [no]: yes\n  Do you want to call peaks? (yes/no) [no]: yes\n  Generate consensus counts from Design merge column? (yes/no) [no]: yes\n  Peak caller: [lanceotron/macs/homer/seacr]: lanceotron\n  Do you want to make a UCSC hub? (yes/no) [no]: yes\n  UCSC hub directory: [seqnado_output/hub/]: seqnado_output/hub/\n  What is your email address? [email@example.com]: email for UCSC\n  Color by (for UCSC hub): [samplename]: samplename\n  Generate GEO submission files (MD5Sums, read count summaries...)? (yes/no) [no]: yes\n  Perform plotting? (yes/no) [no]: yes\n  Path to bed file with coordinates for plotting [None]: \n  Path to bed file with genes. [None]: \n  Directory '2025-02-11_chip_cchahrou_project/' has been created with the 'config_chip.yml' file.\n</code></pre> <p>This will generate the following files:</p> <pre><code>$ tree 2025-02-11_chip_cchahrou_project/\n\n2025-02-11_chip_cchahrou_project/\n\u251c\u2500\u2500 config_chip.yml\n\u2514\u2500\u2500 fastq/\n\n1 directory, 1 file\n</code></pre>"},{"location":"pipeline/#check-the-tool-options","title":"Check the tool options","text":"<p>In the newly created config yaml file, check the tool options especially for rna quantification!</p>"},{"location":"pipeline/#edit-the-configuration-file-if-required","title":"Edit the configuration file (if required)","text":"<p>The configuration file can be edited manually if required e.g. using <code>nano</code> or the VS Code text editor. Use this if you have made an error in the configuration file or if you want to change it for any other reason.</p> <p>Warning</p> <p>If you edit the configuration file manually, you must ensure that it is valid YAML syntax (ensure that you do not delete any colons, commas, or change the indentation). </p> <pre><code>nano config_chip.yml # Note to exit nano press ctrl+x and then \"y\" followed by \"enter\" to save\n</code></pre>"},{"location":"pipeline/#organise-your-fastq-files","title":"Organise your fastq files","text":"<p>use symlinks from your raw_data:</p> <pre><code>cd 2025-02-11_chip_cchahrou_project/fastq\n\nln -s /path/to/raw_data/SampleName_S1_L001_R1_001.fastq.gz samplename1_Antibody_R1.fastq.gz\nln -s /path/to/raw_data/SampleName_S1_L001_R2_001.fastq.gz samplename1_Antibody_R2.fastq.gz\n</code></pre>"},{"location":"pipeline/#infer-sample-names-from-fastq-file-names","title":"Infer sample names from fastq file names","text":"<p>If the fastq files are named in a way that seqnado can infer the sample names, then a design file will be generated automatically:</p> <p>ChIP-seq</p> <ul> <li>samplename1_Antibody_R1.fastq.gz</li> <li>samplename1_Antibody_R2.fastq.gz</li> <li>samplename1_Input_1.fastq.gz</li> <li>samplename1_Input_2.fastq.gz</li> </ul> <p>For ATAC-seq:</p> <ul> <li>sample-name-1_R1.fastq.gz</li> <li>sample-name-1_R2.fastq.gz</li> <li>sample-name-1_1.fastq.gz</li> <li>sample-name-1_2.fastq.gz</li> </ul> <p>For RNA-seq:</p> <ul> <li>sample-name-1_R1.fastq.gz</li> <li>sample-name-1_R2.fastq.gz</li> <li>sample-name-1_1.fastq.gz</li> <li>sample-name-1_2.fastq.gz</li> </ul>"},{"location":"pipeline/#design-file","title":"Design file","text":"<p>If the fastq files are not named in a way that seqnado can infer the sample names, then a design file can be generated using the <code>seqnado-design</code> command. You'll need to enter the working directory and generate a design file:</p> <pre><code>cd ..\nseqnado-design chip fastq/* \n# Note that you can use tab completion to complete the path to the fastq files\n</code></pre> <p>This will generate a design file called <code>design.csv</code> in the working directory.</p> <p>Warning</p> <p>You need to specify the fastq files in the command line to use for the design generation e.g. in the current working directory: <pre><code>seqnado-design chip *.fastq.gz\n</code></pre></p>"},{"location":"pipeline/#merging-replicates-or-samples","title":"Merging replicates or samples","text":"<p>To merge samples for counting or bigwig/peak generation add a merge column to the design file</p> <pre><code>sample_name,r1,r2,scale_group,merge\natac,/ceph/project/milne_group/cchahrou/software/SeqNado/2025-02-11_chip_cchahrou_project/atac_1.fastq.gz,/ceph/project/milne_group/cchahrou/software/SeqNado/2025-02-11_chip_cchahrou_project/atac_2.fastq.gz,all,merge_group\natac2,/ceph/project/milne_group/cchahrou/software/SeqNado/2025-02-11_chip_cchahrou_project/atac_1.fastq.gz,/ceph/project/milne_group/cchahrou/software/SeqNado/2025-02-11_chip_cchahrou_project/atac_2.fastq.gz,all,merge_group\n</code></pre> <p>This will merge both to make a <code>merge_group</code> bigwig and peak file</p> <p>Consensus counts can be made from the merged peaks when consensus_counts is True in config yaml for ATAC or ChIP</p>"},{"location":"pipeline/#atacrna-seq-design-file","title":"ATAC|RNA-seq design file","text":"<p>An ATAC-seq or RNA-seq design file should look something like this:</p> <pre><code>sample,r1,r2\nrna,/path/to/fastq/rna_2.fastq.gz,/path/to/fastq/rna_1.fastq.gz\n</code></pre> <p>Note</p> <p>The design file is a CSV file with the following columns:   * <code>sample</code> - The sample name. Altering this will change the name of the output files so can be useful for renaming samples.   * <code>r1</code> - The path to the read 1 fastq file   * <code>r2</code> - The path to the read 2 fastq file</p>"},{"location":"pipeline/#chip-seq-design-file","title":"ChIP-seq design file","text":"<p>A ChIP assay design file should look something like this:</p> <pre><code>sample_name,ip,control,ip_r1,ip_r2,control_r1,control_r2,scale_group\nchip-rx,MLL,input,fastq/chip-rx_MLL_1.fastq.gz,fastq/chip-rx_MLL_2.fastq.gz,fastq/chip-rx_input_1.fastq.gz,fastq/chip-rx_input_2.fastq.gz,all\n</code></pre> <p>Note</p> <p>The design file is a CSV file with the following columns:   * <code>sample</code> - The sample name. Altering this will change the name of the output files so can be useful for renaming samples.   * <code>ip_r1</code> - The path to the IP read 1 fastq file   * <code>ip_r2</code> - The path to the IP read 2 fastq file   * <code>control_r1</code> - The path to the control read 1 fastq file   * <code>control_r2</code> - The path to the control read 2 fastq file   * <code>ip</code> - The name of the IP sample   * <code>control</code> - The name of the control sample</p>"},{"location":"pipeline/#rna-seq-design-file","title":"RNA-seq design file","text":"<p>An RNA-seq design file should look something like this:</p> <pre><code>sample,r1,r2\nrna,/path/to/fastq/rna_2.fastq.gz,/path/to/fastq/rna_1.fastq.gz\n</code></pre> <p>If you want to run DeSeq2, then you will need to add an additional column to the design file to indicate which samples are in the control group:</p> <pre><code>sample,r1,r2,deseq2\nrna1,/path/to/fastq/rna1_2.fastq.gz,/path/to/fastq/rna1_1.fastq.gz,control\nrna2,/path/to/fastq/rna2_2.fastq.gz,/path/to/fastq/rna2_1.fastq.gz,control\nrna3,/path/to/fastq/rna3_2.fastq.gz,/path/to/fastq/rna3_1.fastq.gz,control\nrna4,/path/to/fastq/rna4_2.fastq.gz,/path/to/fastq/rna4_1.fastq.gz,treated\nrna5,/path/to/fastq/rna5_2.fastq.gz,/path/to/fastq/rna5_1.fastq.gz,treated\nrna6,/path/to/fastq/rna6_2.fastq.gz,/path/to/fastq/rna6_1.fastq.gz,treated\n</code></pre>"},{"location":"pipeline/#running-the-pipeline","title":"Running the pipeline","text":""},{"location":"pipeline/#ensure-files-are-in-the-correct-location","title":"Ensure files are in the correct location","text":"<p>Before running the pipeline, ensure that the fastq files, and design are in the correct location:</p> <pre><code># Fastq files\nln -s /path/to/fastq_files/ /path/to/working-directory/made-by-seqnado-config/\n\n# Design\nmv /path/to/design.csv /path/to/working-directory/made-by-seqnado-config/\n</code></pre>"},{"location":"pipeline/#check-you-are-in-the-correct-directory","title":"Check you are in the correct directory","text":"<pre><code>$ ls -l\n-rw-r--r-- 1 asmith asmithgrp    1845 Jan 13 10:50 config_rna.yml\n-rw-r--r-- 1 asmith asmithgrp   14784 Jan 13 10:50 deseq2_test.qmd\n-rw-r--r-- 1 asmith asmithgrp     155 Jan 13 14:40 design.csv\n-rw-r--r-- 1 asmith asmithgrp 3813176 Jan 13 10:50 rna_1.fastq.gz\n-rw-r--r-- 1 asmith asmithgrp 3836966 Jan 13 10:50 rna_2.fastq.gz\n</code></pre>"},{"location":"pipeline/#ensure-that-the-pipeline-will-not-stop-when-you-log-out","title":"Ensure that the pipeline will not stop when you log out","text":"<pre><code>screen -S NAME_OF_SESSION\n\n# to exit screen session\n  ctrl+a d \n\n# or \n\ntmux new -s NAME_OF_SESSION\n\n# to detach from tmux session\n  ctrl+b d\n</code></pre>"},{"location":"pipeline/#check-you-have-activated-the-conda-environment","title":"Check you have activated the conda environment","text":"<pre><code>conda activate seqnado\n</code></pre>"},{"location":"pipeline/#run-the-pipeline","title":"Run the pipeline","text":"<p>The pipeline can be run using the following command:</p> <pre><code>seqnado [atac|chip|rna|snp] -c &lt;number of cores&gt; --preset [ss|ls] \n# additional options\n--queue/-q [short|long] --scale-resource/-s &lt;factor to multiply resources&gt; \n</code></pre> <p>An actual example would be:</p> <pre><code>seqnado rna -c 8 --preset ss -q short \n</code></pre> <p>Note</p> <ul> <li>To visualise which tasks will be performed by the pipeline before running. <code>seqnado atac -c 1 --preset ss --dag | dot -Tpng &gt; dag.png</code></li> </ul>"},{"location":"pipeline/#pipeline-errors","title":"Pipeline Errors","text":"<p>Check the log file for errors:</p> <pre><code># Look at all of the log files\ncat seqnado_error.log\n\n# Look for errors in the log files\ncat seqnado_error.log | grep exception -A 10 -B 10\n</code></pre>"}]}